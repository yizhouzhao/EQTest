{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from BuildAnimation import *\n",
    "\n",
    "# ab = AnimationBuilder(build_single_person_scene_two_poses)\n",
    "\n",
    "# ab.maya_controller.UndoToBeginning(max_step=1000)\n",
    "\n",
    "# ab.BuildScene()\n",
    "\n",
    "# ab.BuildDefaultFrame()\n",
    "\n",
    "# endFrame_node = ab.pg.node_dict[\"end frame\"]\n",
    "\n",
    "# endFrame_node.next_frame\n",
    "\n",
    "# ab.maya_controller.SetCurrentTimeFrame(endFrame_node.next_frame)\n",
    "\n",
    "# ab.BuildFrame(endFrame_node)\n",
    "\n",
    "# ab.maya_controller.ScreenShot(\"E:/Temp/Test0\")\n",
    "\n",
    "# ab.pg.node_dict\n",
    "\n",
    "# endBody = ab.pg.node_dict['end body']\n",
    "\n",
    "# endBody.chest_leaf.selected_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test AOG2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Raven.BuildTree2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = build_scene()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene.node_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg = scene.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'init frame': Frame.init frame,\n",
       " 'transform': Layout.transform,\n",
       " 'relation': Layout.relation,\n",
       " 'animation1': Animation.animation1,\n",
       " 'motion1': Layout.motion1,\n",
       " 'emotion1': Layout.emotion1,\n",
       " 'motion2': Layout.motion2,\n",
       " 'emotion2': Layout.emotion2,\n",
       " 'animation2': Animation.animation2}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.node_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 2]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.node_dict['transform'].position_leaf.relativePosition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elder\n",
      "society\n"
     ]
    }
   ],
   "source": [
    "print(pg.node_dict['relation'].generation)\n",
    "print(pg.node_dict['relation'].relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salute\n",
      "1.5369231099594862\n",
      "Acknowledging\n",
      "1.9825480776170759\n"
     ]
    }
   ],
   "source": [
    "print(pg.node_dict['motion1'].selected_motion)\n",
    "print(pg.node_dict['motion1'].start_time)\n",
    "print(pg.node_dict['motion2'].selected_motion)\n",
    "print(pg.node_dict['motion2'].start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sad\n",
      "Neutral\n",
      "-23.833974703201683\n",
      "Dissatisfied\n",
      "Mock\n",
      "-17.163012815051697\n"
     ]
    }
   ],
   "source": [
    "print(pg.node_dict['emotion1'].start_emotion)\n",
    "print(pg.node_dict['emotion1'].end_emotion)\n",
    "print(pg.node_dict['emotion1'].start_time)\n",
    "print(pg.node_dict['emotion2'].start_emotion)\n",
    "print(pg.node_dict['emotion2'].end_emotion)\n",
    "print(pg.node_dict['emotion2'].start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\researches\\\\EQTest\\\\SocialAffordance'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAD_DICT = {}\n",
    "\n",
    "# with open(\"../data/NRC-VAD-Lexicon.txt\") as f:\n",
    "#     for c, line in enumerate(f.readlines()):\n",
    "#         if c == 0:\n",
    "#             continue\n",
    "#         line_info = line.strip().split(\"\\t\")\n",
    "#         #print(line_info)\n",
    "#         VAD_DICT[line_info[0]] = [float(line_info[1]), float(line_info[2]), float(line_info[3])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.125663, 0.22385100000000002]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_relation_emotion_scores(pg, G_EMOTION2VAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.2810000000000001, 1.2610000000000001]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_relation_motion_scores(pg, G_MOTION2VAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.26305799999999996, 0.482745]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_motion_emotion_scores(pg, G_MOTION2VAD, G_EMOTION2VAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_survey(label_path):\n",
    "    survey = []\n",
    "    with open(label_path, \"r\") as f:\n",
    "        for c, line in enumerate(f.readlines()):\n",
    "            line_info = line.strip().split(\",\")\n",
    "            #print(c)\n",
    "            sample_info = line_info[0].split(\"_\")\n",
    "            #print(item)\n",
    "            item = {\"m1\": sample_info[0], \"e11\": sample_info[1], \"e12\": sample_info[2],\n",
    "                   \"m2\": sample_info[3], \"e21\": sample_info[4], \"e22\": sample_info[5],\n",
    "                   \"d\": sample_info[6], \"t\": sample_info[7]}\n",
    "            label_info = line_info[1].split(\"_\")\n",
    "            item[\"quality\"] = label_info[0]\n",
    "            item[\"dominance\"] = label_info[1]\n",
    "            item[\"intimacy\"] = label_info[2]\n",
    "\n",
    "            survey.append(item)\n",
    "    \n",
    "    return survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey = load_survey(\"../data/label2.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'m1': 'Wiping',\n",
       " 'e11': 'Tired',\n",
       " 'e12': 'Surprise',\n",
       " 'm2': 'Whatever',\n",
       " 'e21': 'Confused',\n",
       " 'e22': 'Sad',\n",
       " 'd': '4',\n",
       " 't': '1',\n",
       " 'quality': 'Good',\n",
       " 'dominance': 'Character two',\n",
       " 'intimacy': 'Close'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.37572500000000003, 0.12925]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_relation_emotion_scores_survey(survey[1], G_EMOTION2VAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.21766666666666656, 0.20833333333333348]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_relation_motion_scores_survey(survey[1], G_MOTION2VAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8583910000000001, -0.13824]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_motion_emotion_scores_survey(survey[1], G_MOTION2VAD, G_EMOTION2VAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.0182293391045865]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_time_scores(pg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.4189385332046727]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_time_scores_survey(survey[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = torch.randn(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.3897, -1.0315, -0.8528, -1.4636, -0.2303,  0.0576,  1.2019])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s_pg = torch.Tensor(get_pg_score_list(pg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s_survey = torch.Tensor(get_survey_score_list(survey[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    while True:\n",
    "        item = np.random.choice(survey)\n",
    "        if item['quality'] == \"Good\":\n",
    "            break\n",
    "    \n",
    "    pg = scene.sample()\n",
    "    s_pg = torch.Tensor(get_pg_score_list(pg))\n",
    "    s_survey = torch.Tensor(get_survey_score_list(survey[0]))\n",
    "    thetas = thetas + 0.1 * (s_pg -s_survey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.9413e+00, -6.7144e+00,  2.8066e-01,  1.1938e-02,  4.0875e-01,\n",
       "         1.4030e+00,  1.4542e+01])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_good_scores = []\n",
    "survey_bad_scores = []\n",
    "for i in range(100,200):\n",
    "    item = survey[i]\n",
    "    item_score = torch.Tensor(get_survey_score_list(item)).dot(thetas).item()\n",
    "    if item['quality'] == \"Good\":\n",
    "        survey_good_scores.append(item_score)\n",
    "    elif item['quality'] == \"Bad\":\n",
    "        survey_bad_scores.append(item_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-24.222471237182617"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(survey_bad_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-27.957227616083053"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(survey_good_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
